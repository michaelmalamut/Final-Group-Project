{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Life Expentancy Determinator by Countries Worldwide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from path import Path\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data for PCA\n",
    "* Here we will need load, clean up, and scale the dataset\n",
    "* Current cleanup steps we can determine are:\n",
    "    * Remove features that do not apply to all countries\n",
    "    * Focus on a subset of more recent years (maybe from 2010) forward as data is more prevalent in those years\n",
    "    * Remove features that do not have hardy data\n",
    "    * Determine if we should rationalize certain features where data does not exist\n",
    "    * Group data by years then take the mean so that data is one value per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the worldbank_data.csv dataset. Initially we will only be using a database to process and store data.\n",
    "file_path = \"Resources/worldbank_data.csv\"\n",
    "worldbank_df = pd.read_csv(file_path)\n",
    "worldbank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data with StandardScaler().\n",
    "scaler = StandardScaler().fit(x)\n",
    "x_scaled = scaler.transform(x)\n",
    "x_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing Data Dimensions Using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PCA to reduce dimension to three principal components.\n",
    "pca = PCA(n_components=3)\n",
    "x_pca = pca.fit_transform(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the three principal components.  Will need to test how many PC's is best fit, could be more than 3.\n",
    "pcs_df = pd.DataFrame(data=x_pca, columns=[\"PC1\", \"PC2\", \"PC3\"])\n",
    "pcs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Using K-Means\n",
    "\n",
    "#### Finding the Best Value for `k` Using the Elbow Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an elbow curve to find the best value for K.\n",
    "# Find the best value for K\n",
    "inertia = []\n",
    "k = list(range(1, 11))\n",
    "\n",
    "# Calculate the inertia for the range of K values\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(pcs_df)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "# Create the elbow curve\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "df_elbow.hvplot.line(x=\"k\", y=\"inertia\", xticks=k, title=\"Elbow Curve\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running K-Means with `k=?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the K-Means model. Define clusters before running\n",
    "model = KMeans(n_clusters=?, random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(pcs_df)\n",
    "\n",
    "# Predict clusters\n",
    "predictions = model.predict(pcs_df)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatentate the worldbank_df and pcs_df DataFrames on the same columns.\n",
    "merged_df= pd.merge(worldbank_df, pcs_df, left_index=True, right_index=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Add a new column, \"Class\" to the merged_df DataFrame that holds the predictions.\n",
    "mergeddf[\"class\"] = model.labels_\n",
    "pcs_df.head()\n",
    "\n",
    "# Print the shape of the merged_df\n",
    "print(merged_df.shape)\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Results\n",
    "\n",
    "#### 3D-Scatter with Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a 3D-Scatter with the PCA data and the clusters\n",
    "fig = px.scatter_3d(merged_df, x='PC1', y='PC2', z='PC3',color='class', hover_name='x', hover_data=['y'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data to create the scatter plot\n",
    "X_cluster = merged_df[['x', 'y']].copy()\n",
    "X_cluster_scaled = MinMaxScaler().fit_transform(X_cluster)\n",
    "X_cluster_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame that has the scaled data with the clustered_df DataFrame index.\n",
    "plot_df = pd.DataFrame(X_cluster_scaled, columns=['x', y'], index=clustered_df.index)\n",
    "plot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hvplot.scatter plot using x=\"x\" and y=\"y\".\n",
    "plot_df.hvplot.scatter(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    hover_cols=[\"Define\"],\n",
    "    by=\"Class\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
