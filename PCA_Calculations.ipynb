{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Life Expentancy Determinator by Countries Worldwide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from path import Path\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data for PCA\n",
    "* Here we will need load, clean up, and scale the dataset\n",
    "* Current cleanup steps we can determine are:\n",
    "    * Remove features that do not apply to all countries\n",
    "    * Focus on a subset of more recent years (maybe from 2010) forward as data is more prevalent in those years\n",
    "    * Remove features that do not have hardy data\n",
    "    * Determine if we should rationalize certain features where data does not exist\n",
    "    * Group data by years then take the mean so that data is one value per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the worldbank_data.csv dataset. Initially we will only be using a database to process and store data.\n",
    "file_path = \"Resources/worldbank_data.csv\"\n",
    "worldbank_df = pd.read_csv(file_path)\n",
    "worldbank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldbank_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldbank_df.rename(columns = {'Unnamed: 0':'Country'}, inplace = True)\n",
    "worldbank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame that holds only the countries names.\n",
    "country_names_df = worldbank_df.filter(['Country'], axis=1)\n",
    "#country_names_df = country_names_df.set_index('Symbol')\n",
    "country_names_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Country' column since it's not going to be used on the clustering algorithm.\n",
    "worldbank_df.drop('Country', axis=1, inplace=True)\n",
    "#worldbank_df = worldbank_df.set_index('Symbol')\n",
    "worldbank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute NaN values using SKlearn Imputer\n",
    "imputer = SimpleImputer(strategy='mean', missing_values=np.nan)\n",
    "imputer = imputer.fit(worldbank_df[['NY.GDP.MKTP.CN','NY.GDP.PCAP.CN','NY.GDP.PCAP.CD','NY.GDP.MKTP.CD','TM.UVI.MRCH.XD.WD','TX.VAL.MRCH.WL.CD','TM.VAL.MRCH.RS.ZS','TX.VAL.MRCH.XD.WD','NY.ADJ.DCO2.CD','SE.SEC.DURS','AG.LND.FRST.ZS','EN.POP.DNST','AG.LND.FRST.K2','SP.DYN.LE00.IN','SP.RUR.TOTL','TM.VAL.MRCH.XD.WD','EG.ELC.ACCS.ZS','SH.TBS.INCD','SP.DYN.LE00.FE.IN','SP.DYN.CBRT.IN','TX.UVI.MRCH.XD.WD','EG.ELC.ACCS.UR.ZS','NY.ADJ.DMIN.CD','SP.URB.TOTL','SE.PRM.AGES','TX.QTY.MRCH.XD.WD','AG.LND.TOTL.K2','PA.NUS.FCRF','SP.URB.GROW','PA.NUS.ATLS','SP.DYN.TFRT.IN','SP.POP.GROW','SP.RUR.TOTL.ZS','TM.QTY.MRCH.XD.WD','TX.VAL.MRCH.HI.ZS','TX.VAL.MRCH.RS.ZS','NY.ADJ.DNGY.CD','SE.PRM.DURS','TM.VAL.MRCH.WL.CD','NY.ADJ.AEDU.GN.ZS','SP.POP.TOTL','SP.URB.TOTL.IN.ZS','TM.VAL.MRCH.HI.ZS','TT.PRI.MRCH.XD.WD','SE.SEC.AGES','SP.DYN.CDRT.IN','SP.DYN.LE00.MA.IN','SP.RUR.TOTL.ZG'\n",
    "]])\n",
    "worldbank_df[['NY.GDP.MKTP.CN','NY.GDP.PCAP.CN','NY.GDP.PCAP.CD','NY.GDP.MKTP.CD','TM.UVI.MRCH.XD.WD','TX.VAL.MRCH.WL.CD','TM.VAL.MRCH.RS.ZS','TX.VAL.MRCH.XD.WD','NY.ADJ.DCO2.CD','SE.SEC.DURS','AG.LND.FRST.ZS','EN.POP.DNST','AG.LND.FRST.K2','SP.DYN.LE00.IN','SP.RUR.TOTL','TM.VAL.MRCH.XD.WD','EG.ELC.ACCS.ZS','SH.TBS.INCD','SP.DYN.LE00.FE.IN','SP.DYN.CBRT.IN','TX.UVI.MRCH.XD.WD','EG.ELC.ACCS.UR.ZS','NY.ADJ.DMIN.CD','SP.URB.TOTL','SE.PRM.AGES','TX.QTY.MRCH.XD.WD','AG.LND.TOTL.K2','PA.NUS.FCRF','SP.URB.GROW','PA.NUS.ATLS','SP.DYN.TFRT.IN','SP.POP.GROW','SP.RUR.TOTL.ZS','TM.QTY.MRCH.XD.WD','TX.VAL.MRCH.HI.ZS','TX.VAL.MRCH.RS.ZS','NY.ADJ.DNGY.CD','SE.PRM.DURS','TM.VAL.MRCH.WL.CD','NY.ADJ.AEDU.GN.ZS','SP.POP.TOTL','SP.URB.TOTL.IN.ZS','TM.VAL.MRCH.HI.ZS','TT.PRI.MRCH.XD.WD','SE.SEC.AGES','SP.DYN.CDRT.IN','SP.DYN.LE00.MA.IN','SP.RUR.TOTL.ZG'\n",
    "]] = imputer.transform(worldbank_df[['NY.GDP.MKTP.CN','NY.GDP.PCAP.CN','NY.GDP.PCAP.CD','NY.GDP.MKTP.CD','TM.UVI.MRCH.XD.WD','TX.VAL.MRCH.WL.CD','TM.VAL.MRCH.RS.ZS','TX.VAL.MRCH.XD.WD','NY.ADJ.DCO2.CD','SE.SEC.DURS','AG.LND.FRST.ZS','EN.POP.DNST','AG.LND.FRST.K2','SP.DYN.LE00.IN','SP.RUR.TOTL','TM.VAL.MRCH.XD.WD','EG.ELC.ACCS.ZS','SH.TBS.INCD','SP.DYN.LE00.FE.IN','SP.DYN.CBRT.IN','TX.UVI.MRCH.XD.WD','EG.ELC.ACCS.UR.ZS','NY.ADJ.DMIN.CD','SP.URB.TOTL','SE.PRM.AGES','TX.QTY.MRCH.XD.WD','AG.LND.TOTL.K2','PA.NUS.FCRF','SP.URB.GROW','PA.NUS.ATLS','SP.DYN.TFRT.IN','SP.POP.GROW','SP.RUR.TOTL.ZS','TM.QTY.MRCH.XD.WD','TX.VAL.MRCH.HI.ZS','TX.VAL.MRCH.RS.ZS','NY.ADJ.DNGY.CD','SE.PRM.DURS','TM.VAL.MRCH.WL.CD','NY.ADJ.AEDU.GN.ZS','SP.POP.TOTL','SP.URB.TOTL.IN.ZS','TM.VAL.MRCH.HI.ZS','TT.PRI.MRCH.XD.WD','SE.SEC.AGES','SP.DYN.CDRT.IN','SP.DYN.LE00.MA.IN','SP.RUR.TOTL.ZG'\n",
    "]])\n",
    "worldbank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=worldbank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data with StandardScaler().\n",
    "scaler = StandardScaler().fit(x)\n",
    "x_scaled = scaler.transform(x)\n",
    "x_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing Data Dimensions Using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PCA to reduce dimension to three principal components.\n",
    "pca = PCA(n_components=3)\n",
    "pca = pca.fit(x_scaled)\n",
    "X_pca = pca.transform(x_scaled)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the three principal components.  Will need to test how many PC's is best fit, could be more than 3.\n",
    "pcs_df = pd.DataFrame(data=X_pca, columns=[\"PC1\", \"PC2\", \"PC3\"])\n",
    "pcs_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Using K-Means\n",
    "\n",
    "#### Finding the Best Value for `k` Using the Elbow Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an elbow curve to find the best value for K.\n",
    "# Find the best value for K\n",
    "inertia = []\n",
    "k = list(range(1,11))\n",
    "\n",
    "# Calculate the inertia for the range of K values\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(pcs_df)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "# Create the elbow curve\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "df_elbow.hvplot.line(x=\"k\", y=\"inertia\", xticks=k, title=\"Elbow Curve\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running K-Means with `k=?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the K-Means model. Define clusters before running\n",
    "model = KMeans(n_clusters=5, random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(pcs_df)\n",
    "\n",
    "# Predict clusters\n",
    "predictions = model.predict(pcs_df)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatentate the worldbank_df and pcs_df DataFrames on the same columns.\n",
    "merged_df= pd.merge(worldbank_df, pcs_df, left_index=True, right_index=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Add a new column, \"Country\" to the clustered_df DataFrame \n",
    "merged_df[\"Country\"] = country_names_df[\"Country\"]\n",
    "\n",
    "#  Add a new column, \"Class\" to the clustered_df DataFrame that holds the predictions.\n",
    "merged_df[\"class\"] = model.labels_\n",
    "pcs_df.head()\n",
    "\n",
    "# Print the shape of the clustered_df\n",
    "print(merged_df.shape)\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to AWS RDS Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Configure settings for RDS\n",
    "# mode = \"append\"\n",
    "# jdbc_url=\"jdbc:postgresql://module16.ckjmyyscgo5g.us-east-1.rds.amazonaws.com:5432/module16db\"\n",
    "# config = {\"user\":\"postgres\", \n",
    "#           \"password\": \"finalprojectgroup3\", \n",
    "#           \"driver\":\"org.postgresql.Driver\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write merged_df to table in RDS\n",
    "# merged_df.write.jdbc(url=jdbc_url, table='merged_data', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_48364\\2001345985.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcreds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'psycopg2'"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import config as creds\n",
    "\n",
    "\n",
    "def connect():\n",
    "    \n",
    "    # Set up a connection to the postgres server.\n",
    "    conn_string = \"host=\"+ creds.PGHOST +\" port=\"+ \"5432\" +\" dbname=\"+ creds.PGDATABASE +\" user=\" + creds.PGUSER \\\n",
    "                  +\" password=\"+ creds.PGPASSWORD\n",
    "    \n",
    "    conn = psycopg2.connect(conn_string)\n",
    "    print(\"Connected!\")\n",
    "\n",
    "    # Create a cursor object\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    return conn, cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connecting to DB\n",
    "conn, cursor = connect()\n",
    "\n",
    "# SQL command to create inventory table\n",
    "create_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS test_table(\n",
    "        index INTEGER,\n",
    "        id TEXT PRIMARY KEY NOT NULL,\n",
    "        category TEXT,\n",
    "        image TEXT,\n",
    "        displayName TEXT,\n",
    "        urlHistory TEXT\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "# Execute SQL Command and commit to DB\n",
    "cursor.execute(create_table)\n",
    "conn.commit()\n",
    "\n",
    "# Disconnect from DB\n",
    "disconnect(conn, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Results\n",
    "\n",
    "#### 3D-Scatter with Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a 3D-Scatter with the PCA data and the clusters\n",
    "fig = px.scatter_3d(merged_df, x='PC1', y='PC2', z='PC3',color='class', hover_name='Country', hover_data=['SP.DYN.LE00.MA.IN'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data to create the scatter plot\n",
    "X_cluster = merged_df[['Country', 'SP.DYN.LE00.MA.IN']].copy()\n",
    "X_cluster_scaled = MinMaxScaler().fit_transform(X_cluster)\n",
    "X_cluster_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame that has the scaled data with the clustered_df DataFrame index.\n",
    "plot_df = pd.DataFrame(X_cluster_scaled, columns=['x', y'], index=clustered_df.index)\n",
    "plot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hvplot.scatter plot using x=\"x\" and y=\"y\".\n",
    "plot_df.hvplot.scatter(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    hover_cols=[\"Define\"],\n",
    "    by=\"Class\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
